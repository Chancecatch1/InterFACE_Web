# Comparing AI Agent Modalities in AR-based Collaborative CPR Simulation

This research investigates how different AI agent modalities affect collaboration in AR, using CPR simulation as the experimental context.

## Overview

Two participants (**Team Leader** and **Medication Nurse**) interact with a shared AI agent while navigating cardiac arrest (CPR) scenarios together.

## Research Question

> Which AI agent modalityâ€”text, voice, or embodied agentâ€”is most effective for collaborative CPR simulation in AR?

## AI Agent Modalities

| Modality | Description |
|----------|-------------|
| **Text-only** | Guidance displayed as text on a holographic panel |
| **Voice-only** | Disembodied voice guidance without visual representation |
| **Embodied agent** | Embodied agent that mimics human-like behaviors |

## CPR Scenarios

- **Scenario A**: PEA / Asystole (non-shockable rhythm)
- **Scenario B**: Pulseless VT (shockable rhythm)
- **Scenario C**: Ventricular Fibrillation (shockable rhythm)

## Tech Stack

- **Hardware**: Microsoft HoloLens 2
- **Engine**: Unity 6 (v6000.x)
- **XR Framework**: Mixed Reality Toolkit 3 (MRTK3)
- **AI**: TBD
- **Networking**: Socket.IO / WebSocket

## Measurements

- Task Performance (accuracy, completion time)
- Cognitive Workload (NASA-TLX)
- System Usability (SUS)
- Subjective Preference

## Status

ðŸš§ **Work in Progress**

---

*University of Calgary - ENSF 619 Fall 2025*
